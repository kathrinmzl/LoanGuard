{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Perform univariate and correlation analyses to explore the dataset’s structure, identify key relationships between variables and generate insights relevant to Business Requirement 1\n",
        "    * Business Requirement 1: Data Insights (Conventional Analysis)  \n",
        "        Identify key customer and loan attributes that are most correlated with loan default. Provide visual and statistical insights to help business analysts understand the primary drivers of credit risk.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/LoanDefaultData.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate code that answers Business Requirement 1 and can be used within the Streamlit App\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ignore FutureWarnings for message \"is_categorical_dtype is deprecated\"\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas.core.dtypes.common\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder, where the notebook is stored, to its parent folder\n",
        "* First we access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "* Then we want to make the parent of the current directory the new current directory\n",
        "    * os.path.dirname() gets the parent directory\n",
        "    * os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print(f\"You set a new current directory: {current_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As the variable `LoanID` is a unique identifier for each record, it does not contribute to the prediction and will therefore be dropped for the following analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/LoanDefaultData.csv\")\n",
        "    .drop(['LoanID'], axis=1)\n",
        "    )\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration\n",
        "\n",
        "we will check univariate and multivariate analysis -> todo describe section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Univariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section we examine each variable individually, understand its distribution and check for missing values. This helps us get a clear overview of the dataset before moving on to relationships between variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "# Convert object columns to categorical so that it can be displayed properly in the report\n",
        "df_cat = df.copy()\n",
        "for col in df_cat.select_dtypes(include='object').columns:\n",
        "    df_cat[col] = df_cat[col].astype('category')\n",
        "\n",
        "# Also transform tagret variable to categorical\n",
        "df_cat[\"Default\"] = df_cat[\"Default\"].astype('category')\n",
        "    \n",
        "pandas_report = ProfileReport(df=df_cat, minimal=True)\n",
        "pandas_report.to_notebook_iframe() # needs: pip --upgrade setuptools and pip install notebook ipython==8.24.0  ipykernel ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The profile report confirmed that the dataset contains no missing values\n",
        "* Additionally, it shows that the variables `NumCreditLines` and `LoanTerm` are rather categorical variables than continuous numerical variables, as they have only a limited number of different values. They will be transformed for the following analyses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in [\"NumCreditLines\", \"LoanTerm\"]:\n",
        "    df_cat[col] = df_cat[col].astype('category')\n",
        "\n",
        "df_cat.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To make key observations easier to digest, additional univariate analyses were performed, highlighting distributions, skewness/kurtosis and class balance for both numerical and categorical features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Distribution Analysis of Numerical Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Select numerical columns\n",
        "num_cols = df_cat.select_dtypes(include=np.number).columns\n",
        "\n",
        "# Create summary dataframe\n",
        "summary = df_cat[num_cols].describe().T  # gives count, mean, std, min, 25%, 50%, 75%, max\n",
        "\n",
        "# Add skewness\n",
        "summary['skewness'] = df_cat[num_cols].skew()\n",
        "\n",
        "# Optionally, add kurtosis\n",
        "summary['kurtosis'] = df_cat[num_cols].kurtosis()\n",
        "\n",
        "# Round for better readability\n",
        "summary = summary.round(2)\n",
        "\n",
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The numerical variables in the dataset show a generally well-balanced distribution pattern. Most features (such as Age, Income, LoanAmount, and CreditScore) have skewness values close to 0 and slightly negative kurtosis values around −1.2, indicating approximately symmetric distributions with light tails. This suggests that the dataset does not contain extreme outliers or heavy skewness that would require major transformations (e.g., log or Box-Cox scaling).\n",
        "\n",
        "The following boxplots confirm these observations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "numeric_cols = df_cat.select_dtypes(include=['float64', 'int64']).columns\n",
        "n_cols = 2  # number of plots per row\n",
        "n_rows = (len(numeric_cols) + n_cols - 1) // n_cols  # calculate rows needed\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*2))\n",
        "axes = axes.flatten()  # flatten 2D array for easy indexing\n",
        "\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    sns.boxplot(x=df_cat[col], ax=axes[i], palette=\"Set2\", hue=df_cat[col], legend=False)\n",
        "    axes[i].set_title(f\"{col}\")\n",
        "\n",
        "# Remove any unused subplots\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Distribution Analysis of Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select categorical columns\n",
        "cat_cols = df_cat.select_dtypes(include='category').columns.tolist()\n",
        "\n",
        "# Grid layout for plots\n",
        "n_cols = 3\n",
        "n_rows = (len(cat_cols) + n_cols - 1) // n_cols\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*3))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(cat_cols):\n",
        "    sns.countplot(x=col, data=df_cat, ax=axes[i], hue=col, palette='Set2')\n",
        "    axes[i].set_title(f\"{col} Distribution\")\n",
        "    axes[i].set_xlabel('')\n",
        "    axes[i].set_ylabel('Count')\n",
        "\n",
        "# Remove empty subplots\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The categorical variables in the dataset are generally well balanced, with each feature containing only 2–5 distinct classes. This indicates that the features are not overly granular, making them suitable for analysis and modeling. \n",
        "* The exception is the target variable `Default`, which is imbalanced toward 0 (non-default), reflecting that the majority of borrowers in the dataset did not default, what could already be seen in the \"Data Collection\" Notebook in the \"Target Variable Exploration\" section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overall, the distribution analysis confirms that:\n",
        "* The numerical as well as categorical predictors are well-balanced and suitable for further modeling without extensive preprocessing\n",
        "* The target imbalance in `Default` should be addressed later during model development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
