{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Collection Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and save it as raw data.\n",
        "* Inspect the data and save it under outputs/datasets/collection\n",
        "\n",
        "## Inputs\n",
        "\n",
        "*   Kaggle JSON file - the authentication token.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate Dataset: outputs/datasets/collection/LoanDefaultDataset.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "# for vs code\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import glob\n",
        "# Ignore FutureWarnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder, where the notebook is stored, to its parent folder\n",
        "* First we access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "* Then we want to make the parent of the current directory the new current directory\n",
        "    * os.path.dirname() gets the parent directory\n",
        "    * os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print(f\"You set a new current directory: {current_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fetch data from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install Kaggle package to fetch data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install kaggle==1.7.4.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to authenticate Kaggle to download data in this session, your **authentication token (JSON file)** from Kaggle needs to be stored in the main project repository.\n",
        "* In case you don't have your token yet, please refer to the [Kaggle Documentation](https://www.kaggle.com/docs/api)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once you dropped your `kaggle.json` file in the main working directory, run the cell below, so the token is recognized in the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "#! chmod 600 kaggle.json  # not neccessary in vs code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This project uses the [Loan Default Prediction Dataset](https://www.kaggle.com/datasets/laotse/credit-risk-dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the Kaggle dataset, and destination folder and download it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KaggleDatasetPath = \"laotse/credit-risk-dataset\"\n",
        "DestinationFolder = \"inputs/datasets/raw\"   \n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unzip the downloaded file, delete the zip file and delete the kaggle.json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find all zip files in the folder\n",
        "zip_files = glob.glob(os.path.join(DestinationFolder, \"*.zip\"))\n",
        "\n",
        "# Extract each zip file and then delete it\n",
        "for zip_path in zip_files:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(DestinationFolder)\n",
        "    os.remove(zip_path)  # remove the zip after extracting\n",
        "\n",
        "# Optionally, remove kaggle.json if it exists\n",
        "kaggle_json = os.path.join(os.getcwd(), \"kaggle.json\")\n",
        "if os.path.exists(kaggle_json):\n",
        "    os.remove(kaggle_json)\n",
        "\n",
        "print(\"All ZIP files extracted and deleted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load and Inspect Kaggle data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(f\"inputs/datasets/raw/credit_risk_dataset.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The Dataset contains 32581 rows and 12 columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset consists of 12 variables. All data types are correctly assigned:\n",
        "\n",
        "- **7 Numerical variables** (`person_age`, `person_income`, `person_emp_length`, `loan_amnt`, `loan_int_rate`, `loan_percent_income`, `cb_person_cred_hist_length`) are stored as either `int64` or `float64`\n",
        "- **4 Categorical variables** (`person_home_ownership`, `loan_intent`, `loan_grade`, `cb_person_default_on_file`) are stored as `object` type\n",
        "- **Target variable** `loan_status` is numerical (`int64`), where `0` represents non-default and `1` represents default\n",
        "\n",
        "This indicates that the dataset is **properly typed**, with no immediate data type conversions required before preprocessing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Number of missing values in each column:\")\n",
        "\n",
        "missing_count = df.isna().sum()\n",
        "missing_percent = (df.isna().sum() / len(df)) * 100\n",
        "\n",
        "missing_data = pd.DataFrame({\n",
        "    'Missing Values': missing_count,\n",
        "    'Percentage': missing_percent.round(2)\n",
        "})\n",
        "\n",
        "print(missing_data)\n",
        "\n",
        "print(\"\\nTotal number of missing values in the dataframe:\", df.isna().sum().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The dataset contains minimal missing values overall, with only two variables affected:\n",
        "    - `person_emp_length` has **895 missing values** (2.75% of records)  \n",
        "    - `loan_int_rate` has **3,116 missing values** (9.56% of records)  \n",
        "\n",
        "* All other variables are complete with no missing entries \n",
        "* The proportion of missing data is relatively low, indicating good data quality\n",
        "* Appropriate imputation strategies (such as median or model-based imputation) should be applied to `person_emp_length` and `loan_int_rate` during preprocessing to preserve dataset integrity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary Statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Numerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe().round(2).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe(include='object').T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "cat_cols = df.select_dtypes(include='object').columns\n",
        "\n",
        "for col in cat_cols:\n",
        "    print(f\"{col}: {df[col].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Summary statistics were generated for all variables:\n",
        "\n",
        "    - For **numerical features**, metrics such as `mean`, `std`, `min`, and `max` were reviewed to identify potential outliers or inconsistencies\n",
        "    - For **categorical features**, counts and most frequent categories were inspected to understand variable diversity and dominant groups\n",
        "\n",
        "* Additionally, we examined the distinct values within each categorical variable to ensure that all entries are reasonable and align with expected categories\n",
        "\n",
        "* Overall, this provides a comprehensive first look at both numerical and categorical distributions in the dataset.  \n",
        "    While most variables fall within expected ranges, several numerical features — particularly `person_age`, `person_emp_length` and `person_income` — exhibit unusually high maximum values, suggesting the presence of potential outliers that should be examined or treated during preprocessing to ensure model robustness and reliability.  \n",
        "    No unexpected categories or apparent data entry errors are observed, indicating these features are **clean and ready for encoding** in preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Duplicated Entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duplicates = df.duplicated()\n",
        "df[df.duplicated(keep=False)].sort_values(by=['person_age','person_income'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_duplicates = duplicates.sum()\n",
        "percent_duplicates = (num_duplicates / len(df)) * 100\n",
        "print(f\"Number of duplicate rows: {num_duplicates} ({percent_duplicates:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* To ensure data integrity, the dataset was checked for duplicated rows across all features.  \n",
        "  A total of **165 duplicate rows** were identified, likely due to the fact that this is an artificially created dataset.  \n",
        "* As it is highly unlikely for two borrowers to have identical values for all features, these duplicates should be removed.  \n",
        "  They represent **less than 1% of the dataset**, so dropping them will not significantly reduce the data size.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Target Variable Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The target variable **`loan_status`** indicates whether a borrower has defaulted on their loan (`1`) or not (`0`).  \n",
        "\n",
        "The class distribution is examined to understand the balance between default and non-default cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Distribution of Loan Defaults:\")\n",
        "\n",
        "pd.DataFrame({\n",
        "    'Count': df['loan_status'].value_counts(),\n",
        "    'Percentage (%)': round(df['loan_status'].value_counts(normalize=True) * 100, 2)\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,4))\n",
        "sns.countplot(x='loan_status', data=df, hue= \"loan_status\", palette='Set2')\n",
        "plt.title('Target Variable Distribution: loan_status')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(labels=['0 = No', '1 = Yes']) \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- The target variable shows a **highly imbalanced** distribution\n",
        "- This is important because **imbalanced target classes** can bias models toward the majority class. We will have to perform oversampling in order to increase the representation of the minority class before training a model\n",
        "\n",
        "At this stage, no transformation is applied yet, as the goal is to understand the target before data cleaning and modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Collected dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "file_path = f'outputs/datasets/collection'\n",
        "variable_to_save = df\n",
        "filename = \"LoanDefaultData.csv\"\n",
        "\n",
        "# Try to generate output folder\n",
        "try:\n",
        "    os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "# Save the dataset as csv file for further use\n",
        "variable_to_save.to_csv(f\"{file_path}/{filename}\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusions and Next Steps\n",
        "\n",
        "The dataset appears well-structured and mostly complete. Numerical variables are correctly typed, although a few features (`person_age`, `person_emp_length`, `person_income`) exhibit unusually high maximum values, suggesting potential outliers that should be addressed during preprocessing. Categorical variables are stored as objects, and all observed categories are reasonable and consistent with expectations. Summary statistics indicate that the target variable `loan_status` is imbalanced but suitable for modeling. The dataset was checked for duplicated rows across all features, revealing **165 duplicates** (less than 1% of the data) likely due to the artificial nature of the dataset; these will be removed to maintain data integrity. Minimal missing values exist only in `person_emp_length` and `loan_int_rate`, which can be imputed during preprocessing.\n",
        "\n",
        "\n",
        "Next Steps:\n",
        "* Conduct exploratory data analysis (EDA): visualize univariate distributions and relationships between features and the target variable, to answer Business Requirement 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
