{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Feature Engineering Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*  Evaluate which transformations are beneficial for our dataset\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/datasets/cleaned/TrainSet.csv\n",
        "* inputs/datasets/cleaned/TestSet.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate a list of engineering approaches for each variable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ignore FutureWarnings\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder, where the notebook is stored, to its parent folder\n",
        "* First we access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "* Then we want to make the parent of the current directory the new current directory\n",
        "    * os.path.dirname() gets the parent directory\n",
        "    * os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print(f\"You set a new current directory: {current_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explore variables and think about which apporaches could be useful -> Asses by looking at the profile because some vars are numerical some are categorical. e.g. default, although categorical, is already in the format 0/1, so it wont  need an additional ordinal encoder\n",
        "-> check what discretization and outlier approaches are and if we have to test for them here\n",
        "\n",
        "use feature engineering analysis function to apply a set of feature engineering transformers on the data (num, ordinal enc or outlier) and show which transformer leads to improved distributions/which transformer should be applied to the data in the ml pipeline\n",
        "\n",
        "* checking ordinal encoding results: Category names wil have been transformed to numbers, qqplot and boxpot are not informative in this case  (maybe change function so that it will not be shown??)\n",
        "If all transformations look fine -> apply transformations to train and test sets\n",
        "\n",
        "* numerical transofrm results: applies a range to transformers to the data, only the ones that work. e.g. some cant have negative values, so it wouldnt be applied on such variables. Then evaluate if any numerical transformation did improve the distribution to make it look more normally distributed. look for bell shape in histogram, diagonal in qq plot, boxplot doesnt help in this case. -> if no transofrmation shows an improvement, conclude that no transformation should be applied for this variable\n",
        "\n",
        "\n",
        "Using the results, evaluate your data exploration from the beginning. do you need to apply all transformations that you tought of, or are they not neccessary? e.g. if normalization doesnt make the distribution more nomrally distributed, then you should levae it \n",
        "\n",
        "in the end, run smartr correlation selection to determine which features can be dropped due to correlations with other features\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Cleaned Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "file_path = \"outputs/datasets/cleaned\"\n",
        "\n",
        "TrainSet = pd.read_csv(f\"{file_path}/TrainSet.csv\")\n",
        "TrainSet.head(3)\n",
        "TrainSet.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TestSet = pd.read_csv(f\"{file_path}/TestSet.csv\")\n",
        "TestSet.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To identify potential transformations, we first revisit the Profile Report generated earlier.\n",
        "This allows us to assess:\n",
        "\n",
        "* The distributions of numerical variables (to detect skewness or outliers)\n",
        "* The cardinality and balance of categorical variables\n",
        "* Possible data scaling needs due to large differences in magnitude\n",
        "\n",
        "Based on these insights, we will determine which variables may benefit from transformations such as scaling, normalization or encoding before modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "    \n",
        "# Convert object columns to categorical so that it can be displayed properly in the report\n",
        "TrainSet_cat = TrainSet.copy()\n",
        "for col in TrainSet_cat.select_dtypes(include='object').columns:\n",
        "    TrainSet_cat[col] = TrainSet_cat[col].astype('category')\n",
        "    \n",
        "pandas_report = ProfileReport(df=TrainSet_cat, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ProfileReport suggests different transformations depending on the variable type and distribution.\n",
        "\n",
        "Categorical variables should be handled differently based on whether they are nominal or ordinal. The numerical variables are mostly uniformally distributed, so numerical transformations may help improve model performance. Additionally, numerical variables should be scaled to ensure comparable ranges, which benefits many machine learning algorithms. There are no outliers that have to be treated in this dataset. Finally, correlated features should be identified for possible removal to reduce redundancy.\n",
        "\n",
        "Transformation Steps:\n",
        "1. Categorical variables\n",
        "    * Nominal Variables: OneHotEncoder\n",
        "        * `EmploymentType`, `MaritalStatus`, `LoanPurpose`, `HasMortgage`, `HasDependents`, `HasCoSigner`\n",
        "    * Ordinal Variables: OrdinalEncoder\n",
        "        * `Education`\n",
        "2. Numerical Variables\n",
        "    * `NumCreditLines` and `LoanTerm`: No transformation as they have to be treated as ordinal categorical variables\n",
        "    * All other numerical variables: Numerical transformation, since they do not have a normal distribution \n",
        "3. All Variables: Smart correlated selection, so any correlated features will be removed\n",
        "4. Scaling of numerical variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.stats as stats\n",
        "# for vs code\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from feature_engine import transformation as vt\n",
        "from feature_engine.encoding import OneHotEncoder\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "sns.set(style=\"whitegrid\")\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Categorical Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Nominal Variables: OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 1: Select variables and create a separate DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_engineering= [\"EmploymentType\", \"MaritalStatus\", \"LoanPurpose\", \"HasMortgage\", \"HasDependents\", \"HasCoSigner\"]\n",
        "df_engineering = TrainSet[variables_engineering].copy()\n",
        "df_engineering.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 2: Create engineered variables by applying the encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder(variables=variables_engineering)\n",
        "df_feat_eng = encoder.fit_transform(df_engineering)\n",
        "df_feat_eng.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 3: Assess transformation by comparing engineered variables distribution to original ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for var in variables_engineering:\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import pandas as pd\n",
        "\n",
        "    # Count tables\n",
        "    raw_counts = df_engineering[var].value_counts().reset_index()\n",
        "    raw_counts.columns = [var, \"Count\"]\n",
        "\n",
        "    encoded_counts = (\n",
        "        df_feat_eng.filter(like=var, axis=1)\n",
        "        .sum()\n",
        "        .reset_index()\n",
        "    )\n",
        "    encoded_counts.columns = [\"Encoded Column\", \"Count\"]\n",
        "\n",
        "    # Create figure with 2 plots side by side\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 6))\n",
        "    fig.suptitle(f\"Distribution Comparison for '{var}' (Raw vs Encoded)\", fontsize=14, y=1.05)\n",
        "\n",
        "    # Raw variable countplot\n",
        "    sns.countplot(data=df_engineering, x=var, color=\"#432371\", ax=axes[0])\n",
        "    axes[0].set_title(\"Raw Variable (Countplot)\")\n",
        "    axes[0].set_xlabel(\"\")\n",
        "    axes[0].tick_params(axis=\"x\", rotation=90)\n",
        "\n",
        "    # Encoded variable bar plot\n",
        "    df_feat_eng.filter(like=var, axis=1).sum().plot(\n",
        "        kind=\"bar\", color=\"#432371\", width=0.8, ax=axes[1]\n",
        "    )\n",
        "    axes[1].set_title(\"Encoded Variables (One-Hot Columns)\")\n",
        "    axes[1].tick_params(axis=\"x\", rotation=90)\n",
        "    axes[1].set_xlabel(\"\")\n",
        "    axes[1].set_ylabel(\"Count\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- Show tables below the plots ---\n",
        "    print(\"Count Table (Raw Variable):\")\n",
        "    display(raw_counts)\n",
        "\n",
        "    print(\"\\nCount Table (Encoded Variables):\")\n",
        "    display(encoded_counts)\n",
        "    \n",
        "    print(\"---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* For nominal categorical variables, the OneHotEncoder successfully transformed each category into separate binary columns. Therefore, this transformation will be applied in the pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ordinal Variables: OrdinalEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 1: Select variables and create a separate DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_engineering= [\"Education\", \"Default\"]\n",
        "df_engineering = TrainSet[variables_engineering].copy()\n",
        "df_engineering.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 2: Create engineered variables by applying the encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# encoder = OrdinalEncoder(encoding_method='arbitrary', variables=variables_engineering)\n",
        "# df_feat_eng = encoder.fit_transform(df_engineering)\n",
        "# df_feat_eng.head(3)\n",
        "encoder = OrdinalEncoder(encoding_method='ordered', variables=\"Education\")\n",
        "df_feat_eng = encoder.fit_transform(pd.DataFrame(df_engineering[\"Education\"]), pd.DataFrame(df_engineering[\"Default\"]))\n",
        "df_feat_eng.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 3: Assess transformation by comparing engineered variables distribution to original ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#for var in variables_engineering:\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "var = variables_engineering[0]\n",
        "# Count tables\n",
        "raw_counts = df_engineering[var].value_counts().reset_index()\n",
        "raw_counts.columns = [var, \"Count\"]\n",
        "\n",
        "encoded_counts = df_feat_eng[var].value_counts().reset_index()\n",
        "encoded_counts.columns = [var, \"Count\"]\n",
        "\n",
        "# Create figure with 2 plots side by side\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 6))\n",
        "fig.suptitle(f\"Distribution Comparison for '{var}' (Raw vs Encoded)\", fontsize=14, y=1.05)\n",
        "\n",
        "# Raw variable countplot\n",
        "sns.countplot(data=df_engineering, x=var, color=\"#432371\", ax=axes[0])\n",
        "axes[0].set_title(\"Raw Variable (Countplot)\")\n",
        "axes[0].set_xlabel(\"\")\n",
        "axes[0].tick_params(axis=\"x\", rotation=90)\n",
        "\n",
        "# Encoded variable bar plot\n",
        "sns.countplot(data=df_feat_eng, x=var, color=\"#432371\", ax=axes[1])\n",
        "axes[0].set_title(\"Encoded Variable (Countplot)\")\n",
        "axes[0].set_xlabel(\"\")\n",
        "axes[0].tick_params(axis=\"x\", rotation=90)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show tables below the plots\n",
        "print(\"Count Table (Raw Variable):\")\n",
        "display(raw_counts)\n",
        "\n",
        "print(\"\\nCount Table (Encoded Variables):\")\n",
        "display(encoded_counts)\n",
        "print(\"Class Mapping:\")\n",
        "print(encoder.encoder_dict_)\n",
        "\n",
        "print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The OrdinalEncoder successfully transformed the ordered categorical variables into numeric form while preserving their order. Therefore, this transformation will be applied in the pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Numerical Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It gets a DataFrame as input and applies a defined set of numerical\n",
        "feature engineering transformers. This will help you to decide which transformers to apply to your data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO FUNKTION VEREINFACHEN??\n",
        "\n",
        "import scipy.stats as stats\n",
        "# for vs code\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from feature_engine import transformation as vt\n",
        "sns.set(style=\"whitegrid\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def FeatureEngineeringAnalysis(df, analysis_type=None):\n",
        "    \"\"\"\n",
        "    - used for quick feature engineering on numerical and categorical variables\n",
        "    to decide which transformation can better transform the distribution shape\n",
        "    - Once transformed, use a reporting tool, like ydata-profiling, to evaluate distributions\n",
        "    \"\"\"\n",
        "    check_missing_values(df)\n",
        "    allowed_types = ['numerical']\n",
        "    check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
        "    list_column_transformers = define_list_column_transformers(analysis_type)\n",
        "\n",
        "    # Loop in each variable and engineer the data according to the analysis type\n",
        "    df_feat_eng = pd.DataFrame([])\n",
        "    for column in df.columns:\n",
        "        # create additional columns (column_method) to apply the methods\n",
        "        df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
        "        for method in list_column_transformers:\n",
        "            df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
        "\n",
        "        # Apply transformers in respective column_transformers\n",
        "        df_feat_eng, list_applied_transformers = apply_transformers(\n",
        "            analysis_type, df_feat_eng, column)\n",
        "\n",
        "        # For each variable, assess how the transformations perform\n",
        "        transformer_evaluation(\n",
        "            column, list_applied_transformers, analysis_type, df_feat_eng)\n",
        "\n",
        "    return df_feat_eng\n",
        "\n",
        "\n",
        "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
        "    \"\"\" Check analysis type \"\"\"\n",
        "    if analysis_type is None:\n",
        "        raise SystemExit(\n",
        "            f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
        "    if analysis_type not in allowed_types:\n",
        "        raise SystemExit(\n",
        "            f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
        "\n",
        "\n",
        "def check_missing_values(df):\n",
        "    if df.isna().sum().sum() != 0:\n",
        "        raise SystemExit(\n",
        "            f\"There is a missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
        "\n",
        "\n",
        "def define_list_column_transformers(analysis_type):\n",
        "    \"\"\" Set suffix columns according to analysis_type\"\"\"\n",
        "    if analysis_type == 'numerical':\n",
        "        list_column_transformers = [\n",
        "            \"log_e\", \"log_10\", \"reciprocal\", \"power\", \"box_cox\", \"yeo_johnson\"]\n",
        "\n",
        "    return list_column_transformers\n",
        "\n",
        "\n",
        "def apply_transformers(analysis_type, df_feat_eng, column):\n",
        "\n",
        "    df_feat_eng, list_applied_transformers = FeatEngineering_Numerical(\n",
        "        df_feat_eng, column)\n",
        "\n",
        "    return df_feat_eng, list_applied_transformers\n",
        "\n",
        "\n",
        "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
        "    # For each variable, assess how the transformations perform\n",
        "    print(f\"* Variable Analyzed: {column}\")\n",
        "    print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
        "    for col in [column] + list_applied_transformers:\n",
        "\n",
        "        DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Numerical(df, variable):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    # sns.histplot(data=df, x=variable, kde=True, element=\"step\", ax=axes[0])\n",
        "    sns.histplot(data=df, x=variable, kde=True, ax=axes[0])\n",
        "    stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
        "\n",
        "    axes[0].set_title('Histogram')\n",
        "    axes[1].set_title('QQ Plot')\n",
        "    fig.suptitle(f\"{variable}\", fontsize=30, y=1.05)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def FeatEngineering_Numerical(df_feat_eng, column):\n",
        "    list_methods_worked = []\n",
        "\n",
        "    # LogTransformer base e\n",
        "    try:\n",
        "        lt = vt.LogTransformer(variables=[f\"{column}_log_e\"])\n",
        "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_log_e\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_log_e\"], axis=1, inplace=True)\n",
        "\n",
        "    # LogTransformer base 10\n",
        "    try:\n",
        "        lt = vt.LogTransformer(variables=[f\"{column}_log_10\"], base='10')\n",
        "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_log_10\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_log_10\"], axis=1, inplace=True)\n",
        "\n",
        "    # ReciprocalTransformer\n",
        "    try:\n",
        "        rt = vt.ReciprocalTransformer(variables=[f\"{column}_reciprocal\"])\n",
        "        df_feat_eng = rt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_reciprocal\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_reciprocal\"], axis=1, inplace=True)\n",
        "\n",
        "    # PowerTransformer\n",
        "    try:\n",
        "        pt = vt.PowerTransformer(variables=[f\"{column}_power\"])\n",
        "        df_feat_eng = pt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_power\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_power\"], axis=1, inplace=True)\n",
        "\n",
        "    # BoxCoxTransformer\n",
        "    try:\n",
        "        bct = vt.BoxCoxTransformer(variables=[f\"{column}_box_cox\"])\n",
        "        df_feat_eng = bct.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_box_cox\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_box_cox\"], axis=1, inplace=True)\n",
        "\n",
        "    # YeoJohnsonTransformer\n",
        "    try:\n",
        "        yjt = vt.YeoJohnsonTransformer(variables=[f\"{column}_yeo_johnson\"])\n",
        "        df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_yeo_johnson\"], axis=1, inplace=True)\n",
        "\n",
        "    return df_feat_eng, list_methods_worked\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Numerical Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 1: Select variables and create a separate DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_engineering= TrainSet.select_dtypes(include=['int64', 'float64']).columns.drop([\"NumCreditLines\", \"LoanTerm\", \"Default\"]).tolist()\n",
        "df_engineering = TrainSet[variables_engineering].copy()\n",
        "df_engineering.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Step 2: Create engineered variables by applying the encoder and assess transformation by comparing engineered variables distributions to original ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_engineering = FeatureEngineeringAnalysis(df=df_engineering, analysis_type='numerical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Several numerical transformers were tested, including Log, Log base 10, Reciprocal, Power, Box-Cox and Yeo-Johnson. None of them helped to achieve a bell-shaped distribution or values aligned along the diagonal in the QQ plot. Therefore, no numerical transformation will be applied"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "# Set the file_path and a version tag, which will be the folder name.\n",
        "# It's appropriate since it's a form of version control.\n",
        "version = 'v1'\n",
        "file_path = f'.../{version}'\n",
        "variable_to_save = df # or pipeline\n",
        "filename = \"dataset.csv\" # or \"pipeline.pkl\"\n",
        "\n",
        "# Try to generate output folder\n",
        "try:\n",
        "    os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "# Save the dataset as csv file for further use\n",
        "variable_to_save.to_csv(f\"{file_path}/{filename}\", index=False)\n",
        "\n",
        "# Save the variable as pkl file for further use\n",
        "joblib.dump(value=variable_to_save ,\n",
        "            filename=f\"{file_path}/{filename}\")\n",
        "\n",
        "\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Save the figure as png file for further use\n",
        "plt.savefig(f\"{file_path}/{filename}\", bbox_inches='tight',dpi=150)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusions and Next Steps\n",
        "\n",
        "* Fill in conclusions and next steps"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
