{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Cleaning Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Clean data\n",
        "* Split cleaned dataset into Train and Test sets\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/LoanDefaultData.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate cleaned Train and Test sets, both saved under outputs/datasets/cleaned\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "# for vs code\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from feature_engine.outliers import Winsorizer\n",
        "from feature_engine.imputation import MeanMedianImputer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder, where the notebook is stored, to its parent folder\n",
        "* First we access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "* Then we want to make the parent of the current directory the new current directory\n",
        "    * os.path.dirname() gets the parent directory\n",
        "    * os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print(f\"You set a new current directory: {current_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"outputs/datasets/collection/LoanDefaultData.csv\")\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_var = \"loan_status\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drop duplicate entries\n",
        "\n",
        "In the data collection step we already established that there are some duplicated entries in the dataset. As they account to less than 1 % of data we will drop them from the dataset.\n",
        "\n",
        "Show duplicated entries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duplicates = df.duplicated()\n",
        "df[df.duplicated(keep=False)].sort_values(by=['person_age','person_income'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Duplicates should be dropped before splitting into training and test sets to prevent data leakage, which could artificially inflate model performance. Removing duplicates beforehand also ensures that both sets reflect the true data distribution and that evaluation metrics remain reliable.\n",
        "\n",
        "No duplicated entries remain after dropping them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.drop_duplicates()\n",
        "df[df.duplicated()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Train and Test Set\n",
        "\n",
        "Missing data imputation and outlier treatment should be done after splitting into training and test sets to avoid data leakage. Therefore we now split the data into train and test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df[target_var],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missing Data\n",
        "\n",
        "We first check for missing data in the train set and can confirm that there is some missing data present in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_missing_values(df):\n",
        "    print(\"Number of missing values in each column:\")\n",
        "\n",
        "    missing_count = df.isna().sum()\n",
        "    missing_percent = (df.isna().sum() / len(df)) * 100\n",
        "\n",
        "    missing_data = pd.DataFrame({\n",
        "        'Missing Values': missing_count,\n",
        "        'Percentage': missing_percent.round(2)\n",
        "    })\n",
        "\n",
        "    print(missing_data)\n",
        "\n",
        "    print(\"\\nTotal number of missing values in the dataframe:\", \n",
        "          df.isna().sum().sum())\n",
        "    \n",
        "show_missing_values(TrainSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The Train Set contains missing values in the variables `person_emp_length` and `loan_int_rate`, both with less than 10% of observations missing\n",
        "\n",
        "Given the relatively small proportion of missing data, these values will be handled using **median imputation**. This approach is appropriate since the numerical features are skewed and contain outliers, making the median a more robust measure than the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputer = MeanMedianImputer(imputation_method='median', \n",
        "                            variables=['person_emp_length', 'loan_int_rate'])\n",
        "df_cleaned = imputer.fit_transform(TrainSet)\n",
        "\n",
        "show_missing_values(df_cleaned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare distributions before and after imputing the missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Before imputing missing values:\")\n",
        "missing_cols = ['person_emp_length', 'loan_int_rate']\n",
        "TrainSet[missing_cols].describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"After imputing missing values:\")\n",
        "df_cleaned[missing_cols].describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The summary statistics between the original training dataset and the cleaned dataset are very similar, indicating that the distributions have not been significantly affected by the median imputation. This confirms that the imputation preserved the overall data characteristics, so the same median imputer will now be applied to both the training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputer = MeanMedianImputer(imputation_method='median', \n",
        "                            variables=['person_emp_length', 'loan_int_rate'])\n",
        "TrainSet = imputer.fit_transform(TrainSet)\n",
        "TestSet = imputer.transform(TestSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the previous exploratory analysis, we observed that several numerical variables contained pronounced outliers, mostly in the upper range of their distributions.\n",
        "To mitigate their influence on model performance while preserving the overall data structure, we apply Winsorization on the right tail.\n",
        "\n",
        "This approach caps extreme values at defined thresholds (based on the interquartile range), reducing the impact of outliers without removing observations from the dataset.\n",
        "\n",
        "For `person_income`, `person_age`, and `person_emp_length`, we observed some values that are clearly not realistic. Other numerical variables also show outliers, but they lie within a credible range, so trimming them is not strictly necessary as it would remove potentially useful information. Depending on the model choice, this decision can be revisited; for example, linear models might benefit from a tighter fold to reduce the influence of extreme values.\n",
        "\n",
        "We use a fold of 5 for Winsorization to cap only the most extreme outliers. This way we only target outliers in the variables `person_income`, `person_age`, and `person_emp_length`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply Winsorization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_cols = (TrainSet\n",
        "                .select_dtypes(include=['float64', 'int64'])\n",
        "                .columns\n",
        "                .drop(\"loan_status\").tolist())\n",
        "\n",
        "winsorizer = Winsorizer(capping_method='iqr', fold=5, \n",
        "                        tail='right', variables=numeric_cols)\n",
        "df_winsorized = winsorizer.fit_transform(TrainSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare differences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_outliers(series):\n",
        "    \"\"\"Return the number of outliers in a pandas Series using the IQR method.\"\"\"\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 5 * IQR\n",
        "    upper_bound = Q3 + 5 * IQR\n",
        "    return ((series < lower_bound) | (series > upper_bound)).sum()\n",
        "\n",
        "# Compute outlier counts for each feature before and after cleaning\n",
        "outliers_before = {col: count_outliers(TrainSet[col]) for col in numeric_cols}\n",
        "outliers_after = {\n",
        "    col: count_outliers(df_winsorized[col]) \n",
        "    for col in numeric_cols\n",
        "    }\n",
        "\n",
        "# Combine results into a single DataFrame (one column per feature)\n",
        "outlier_comparison = pd.DataFrame(\n",
        "    [outliers_before, outliers_after], \n",
        "    index=['Outliers Before Cleaning', 'Outliers After Cleaning']).T\n",
        "\n",
        "outlier_comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_cols = 2  \n",
        "n_rows = (len(numeric_cols) + n_cols - 1) // n_cols \n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*2))\n",
        "axes = axes.flatten()  \n",
        "\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    sns.boxplot(x=df_winsorized[col], ax=axes[i], \n",
        "                color=sns.color_palette(\"Set2\")[0])\n",
        "    axes[i].set_title(f\"{col}\")\n",
        "\n",
        "# Remove any unused subplots\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The outlier comparison and boxplots show that all extreme values in the numerical features were effectively removed after applying Winsorization on the right tail. This confirms that the Winsorizer successfully capped high-end outliers without altering the overall data structure. Based on these results, we will apply the same Winsorization procedure to both the training and test sets to ensure consistent preprocessing across the entire modeling pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "winsorizer = Winsorizer(capping_method='iqr', fold=5, \n",
        "                        tail='right', variables=numeric_cols)\n",
        "TrainSet = winsorizer.fit_transform(TrainSet)\n",
        "TestSet = winsorizer.transform(TestSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "file_path = 'outputs/datasets/cleaned'\n",
        "\n",
        "try:\n",
        "    os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "# Save the Train and Test sets as csv files for further use\n",
        "filename = \"TrainSet.csv\"\n",
        "TrainSet.to_csv(f\"{file_path}/{filename}\", index=False)\n",
        "\n",
        "filename = \"TestSet.csv\"\n",
        "TestSet.to_csv(f\"{file_path}/{filename}\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusions and Next Steps\n",
        "\n",
        "We performed key data cleaning steps including:\n",
        "* Removal of duplicate rows\n",
        "* Median imputation for missing values\n",
        "* Winsorization of extreme outliers \n",
        "\n",
        "Further data cleaning actions are not required, as all columns could potentially have predictive power, no columns need removal, and categorical values were consistent in the exploratory analysis.\n",
        "\n",
        "Next Steps:\n",
        "* Prepare data for feature engineering and modeling"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
